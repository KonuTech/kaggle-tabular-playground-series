{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\KonuTech\\\\DataSpellProjects\\\\kaggle-tabular-playground-series-oct-2021\\\\scripts\")\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import product, chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, EShapCalcType, EFeaturesSelectionAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.paramsearch import paramsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ! python scripts\\unzip.py inputs\\tabular-playground-series-oct-2021.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CURRENT_WORKING_DIRECTORY = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUTS = CURRENT_WORKING_DIRECTORY + \"\\\\INPUTS\"\n",
    "SCRIPTS = CURRENT_WORKING_DIRECTORY + \"\\\\SCRIPTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"config.json\"\n",
    "with open(CURRENT_WORKING_DIRECTORY + \"\\\\\" + CONFIG_FILE, encoding='utf-8') as f:\n",
    "    CONFIG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = CONFIG[\"INPUTS\"][\"TRAIN_PATH\"][0]\n",
    "TEST_PATH = CONFIG[\"INPUTS\"][\"TEST_PATH\"][0]\n",
    "TARGET = CONFIG[\"INPUTS\"][\"TARGET\"]\n",
    "INDEX_COL = CONFIG[\"INPUTS\"][\"INDEX_COLUMNS\"]\n",
    "SEP = CONFIG[\"INPUTS\"][\"SEPARATOR\"]\n",
    "DECIMAL = CONFIG[\"INPUTS\"][\"DECIMAL\"]\n",
    "ENCODING = CONFIG[\"INPUTS\"][\"ENCODING\"]\n",
    "DATE_COLUMNS = CONFIG[\"INPUTS\"][\"DATE_COLUMNS\"]\n",
    "FLOAT_PRECISION = CONFIG[\"INPUTS\"][\"FLOAT_PRECISION\"]\n",
    "DTYPE = CONFIG[\"INPUTS\"][\"DTYPE\"]\n",
    "COLUMNS_WITH_NAN_VALUES = CONFIG[\"INPUTS\"][\"COLUMNS_WITH_NAN_VALUES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TRAIN OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    INPUTS + \"\\\\\" + TRAIN_PATH,\n",
    "    index_col=INDEX_COL,\n",
    "    sep=SEP,\n",
    "    encoding=ENCODING,\n",
    "    infer_datetime_format=True,\n",
    "    engine=\"c\",\n",
    "    low_memory=False,\n",
    "    # dtype=DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000000 entries, 0 to 999999\n",
      "Columns: 286 entries, f0 to target\n",
      "dtypes: float64(240), int64(46)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500485\n",
       "0    499515\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[TARGET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "       ...\n",
       "       'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283',\n",
       "       'f284'],\n",
       "      dtype='object', length=285)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_NUMERIC_COLUMNS = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "TRAIN_NUMERIC_COLUMNS = TRAIN_NUMERIC_COLUMNS.drop(TARGET)\n",
    "TRAIN_NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_OBJECT_COLUMNS = train.select_dtypes(include=[\"object\"]).columns\n",
    "TRAIN_OBJECT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TEST OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    INPUTS + \"\\\\\" + TEST_PATH,\n",
    "    index_col=INDEX_COL,\n",
    "    sep=SEP,\n",
    "    encoding=ENCODING,\n",
    "    infer_datetime_format=True,\n",
    "    engine=\"c\",\n",
    "    low_memory=False,\n",
    "    # dtype=DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500000 entries, 1000000 to 1499999\n",
      "Columns: 285 entries, f0 to f284\n",
      "dtypes: float64(240), int64(45)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "       ...\n",
       "       'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283',\n",
       "       'f284'],\n",
       "      dtype='object', length=285)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_NUMERIC_COLUMNS = test.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "TEST_NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_OBJECT_COLUMNS = test.select_dtypes(include=[\"object\"]).columns\n",
    "TEST_OBJECT_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1232754</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449089</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486856</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320681</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290238</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0   f1   f2   f3   f4   f5   f6   f7   f8   f9  ...  f275  f276  \\\n",
       "id                                                         ...               \n",
       "1232754 0.25 0.48 0.01 0.23 0.58 0.48 0.46 0.65 0.57 0.34  ...     0     0   \n",
       "1449089 0.20 0.43 0.09 0.25 0.44 0.43 0.50 0.57 0.55 0.19  ...     1     0   \n",
       "1486856 0.21 0.53 0.45 0.17 0.61 0.34 0.10 0.67 0.58 0.31  ...     0     0   \n",
       "1320681 0.20 0.28 0.09 0.39 0.56 0.42 0.53 0.65 0.43 0.14  ...     0     0   \n",
       "1290238 0.23 0.51 0.02 0.29 0.52 0.41 0.50 0.60 0.49 0.49  ...     0     0   \n",
       "\n",
       "         f277  f278  f279  f280  f281  f282  f283  f284  \n",
       "id                                                       \n",
       "1232754     0     0     0     0     0     0     0     0  \n",
       "1449089     0     0     1     0     1     0     0     0  \n",
       "1486856     0     0     0     0     0     0     0     0  \n",
       "1320681     0     1     0     0     0     1     0     0  \n",
       "1290238     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in [TARGET]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872646</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355316</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0   f1   f2   f3   f4   f5   f6   f7   f8   f9  ...  f275  f276  \\\n",
       "id                                                        ...               \n",
       "872646 0.23 0.36 0.01 0.51 0.45 0.44 0.43 0.60 0.62 0.39  ...     0     0   \n",
       "355316 0.18 0.62 0.02 0.31 0.43 0.52 0.56 0.65 0.67 0.43  ...     0     0   \n",
       "\n",
       "        f277  f278  f279  f280  f281  f282  f283  f284  \n",
       "id                                                      \n",
       "872646     0     0     0     1     0     0     1     0  \n",
       "355316     0     0     0     0     1     0     0     0  \n",
       "\n",
       "[2 rows x 285 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500485\n",
       "0    499515\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1405442</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353550</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0   f1   f2   f3   f4   f5   f6   f7   f8   f9  ...  f275  f276  \\\n",
       "id                                                         ...               \n",
       "1405442 0.28 0.43 0.10 0.45 0.47 0.43 0.07 0.65 0.42 0.28  ...     0     1   \n",
       "1353550 0.23 0.42 0.18 0.26 0.74 0.43 0.50 0.50 0.58 0.16  ...     1     1   \n",
       "\n",
       "         f277  f278  f279  f280  f281  f282  f283  f284  \n",
       "id                                                       \n",
       "1405442     1     0     0     1     0     0     0     0  \n",
       "1353550     0     0     0     0     0     1     0     0  \n",
       "\n",
       "[2 rows x 285 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train shape:  (1000000, 285) \n",
      " y_train shape:  (1000000,) \n",
      " X_test  shape:  (500000, 285) \n",
      " y_test  shape:  None\n"
     ]
    }
   ],
   "source": [
    "print(\" X_train shape: \", X_train.shape, \"\\n\", \"y_train shape: \", y_train.shape, \"\\n\", \"X_test  shape: \", X_test.shape, \"\\n\", \"y_test  shape: \", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = TEST_OBJECT_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features_index = []\n",
    "for column in categorical_features:\n",
    "    categorical_features_index.append(X_train.columns.get_loc(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# labels_dict : {ind_label: count_label}\n",
    "# mu : parameter to tune\n",
    "\n",
    "def create_class_weight(labels_dict, mu=0.15):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_dict = {0: y_train.value_counts()[0], 1: y_train.value_counts()[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 499515, 1: 500485}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FEATURE SELECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selector = CatBoostClassifier(\n",
    "    #     loss_function=\"CrossEntropy\", # class weights takes effect only with Logloss, MultiClass, MultiClassOneVsAll\n",
    "    loss_function=\"CrossEntropy\",\n",
    "    eval_metric=\"AUC\",\n",
    "    custom_metric=['AUC:hints=skip_train~false'],\n",
    "#     custom_metric=['AUC:type=OneVsAll;hints=skip_train~false', 'Accuracy'], # for many classes\n",
    "#     class_weights=class_weights,\n",
    "#     one_hot_max_size=31,\n",
    "    depth=6,\n",
    "    iterations= 25000,\n",
    "    l2_leaf_reg= 3,\n",
    "#     learning_rate= 0.03,\n",
    "    learning_rate= 0.1,\n",
    "    nan_mode=\"Max\",\n",
    "    cat_features=categorical_features_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names= X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features_index, feature_names=feature_names)\n",
    "#test_pool = Pool(X_test, y_test, cat_features=categorical_features_index, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1046953</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439401</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0   f1   f2   f3   f4   f5   f6   f7   f8   f9  ...  f275  f276  \\\n",
       "id                                                         ...               \n",
       "1046953 0.32 0.47 0.02 0.27 0.72 0.34 0.45 0.56 0.45 0.26  ...     0     0   \n",
       "1439401 0.18 0.40 0.40 0.39 0.38 0.44 0.45 0.65 0.44 0.33  ...     0     1   \n",
       "\n",
       "         f277  f278  f279  f280  f281  f282  f283  f284  \n",
       "id                                                       \n",
       "1046953     0     1     0     0     0     1     0     1  \n",
       "1439401     0     0     0     0     1     0     0     0  \n",
       "\n",
       "[2 rows x 285 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test.shape[1]-1\n",
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0-285'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0-' + str(X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f533ed61198f452ba84dbe6e1ed5b6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1 out of 1\n",
      "0:\tlearn: 0.8196709\ttotal: 334ms\tremaining: 2h 19m 13s\n",
      "1:\tlearn: 0.8256714\ttotal: 644ms\tremaining: 2h 14m 13s\n",
      "2:\tlearn: 0.8261086\ttotal: 969ms\tremaining: 2h 14m 32s\n",
      "3:\tlearn: 0.8270506\ttotal: 1.34s\tremaining: 2h 20m 3s\n",
      "4:\tlearn: 0.8272231\ttotal: 1.69s\tremaining: 2h 21m 10s\n",
      "5:\tlearn: 0.8285992\ttotal: 2.01s\tremaining: 2h 19m 52s\n",
      "6:\tlearn: 0.8295996\ttotal: 2.3s\tremaining: 2h 16m 55s\n",
      "7:\tlearn: 0.8298570\ttotal: 2.59s\tremaining: 2h 14m 54s\n",
      "8:\tlearn: 0.8305956\ttotal: 2.89s\tremaining: 2h 13m 48s\n",
      "9:\tlearn: 0.8314642\ttotal: 3.21s\tremaining: 2h 13m 31s\n",
      "10:\tlearn: 0.8320007\ttotal: 3.57s\tremaining: 2h 15m 19s\n",
      "11:\tlearn: 0.8322646\ttotal: 3.94s\tremaining: 2h 16m 34s\n",
      "12:\tlearn: 0.8327947\ttotal: 4.31s\tremaining: 2h 18m\n",
      "13:\tlearn: 0.8335691\ttotal: 4.64s\tremaining: 2h 17m 59s\n",
      "14:\tlearn: 0.8338677\ttotal: 5s\tremaining: 2h 18m 50s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27408/171608277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m summary = selector.select_features(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# X_train, y_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#eval_set=test_pool, # The validation dataset or datasets used for the following processes: overfitting detector, best iteration selection, monitoring metrics changes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfeatures_for_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Features which participate in the selection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnum_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# The number of features to select from features_for_select.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mselect_features\u001b[1;34m(self, X, y, eval_set, features_for_select, num_features_to_select, algorithm, steps, shap_calc_type, train_final_model, verbose, logging_level, plot, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   4015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4016\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_dirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4017\u001b[1;33m             \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_final_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._select_features\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._select_features\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary = selector.select_features(\n",
    "    train_pool, # X_train, y_train\n",
    "    #eval_set=test_pool, # The validation dataset or datasets used for the following processes: overfitting detector, best iteration selection, monitoring metrics changes\n",
    "    features_for_select='0-' + str(X_test.shape[1]-1), # Features which participate in the selection.\n",
    "    num_features_to_select=40, # The number of features to select from features_for_select.\n",
    "    steps=1, # The number of times for training the model. Use more steps for more accurate selection\n",
    "    algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues, # the most accurate method\n",
    "    shap_calc_type=EShapCalcType.Exact, # The method of the SHAP values calculations ordered by accuracy: Approximate, Regular, Exact\n",
    "    train_final_model=True, # If specified, then the model with selected features will be trained after features selection.\n",
    "    #logging_level='Silent', # optimized metric, elapsed time of training, remaining time of training\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['loss_graph']['loss_values'][-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.24102984938730537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary[\"selected_features_names\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['f1',\n",
    " 'f2',\n",
    " 'f3',\n",
    " 'f4',\n",
    " 'f5',\n",
    " 'f6',\n",
    " 'f7',\n",
    " 'f8',\n",
    " 'f12',\n",
    " 'f13',\n",
    " 'f14',\n",
    " 'f15',\n",
    " 'f16',\n",
    " 'f17',\n",
    " 'f18',\n",
    " 'f19',\n",
    " 'f20',\n",
    " 'f22',\n",
    " 'f29',\n",
    " 'f35',\n",
    " 'f36',\n",
    " 'f40',\n",
    " 'f42',\n",
    " 'f44',\n",
    " 'f48',\n",
    " 'f52',\n",
    " 'f53',\n",
    " 'f56',\n",
    " 'f58',\n",
    " 'f63',\n",
    " 'f65',\n",
    " 'f69',\n",
    " 'f71',\n",
    " 'f72',\n",
    " 'f73',\n",
    " 'f74',\n",
    " 'f75',\n",
    " 'f76',\n",
    " 'f77',\n",
    " 'f78',\n",
    " 'f79',\n",
    " 'f81',\n",
    " 'f82',\n",
    " 'f85',\n",
    " 'f90',\n",
    " 'f92',\n",
    " 'f93',\n",
    " 'f94',\n",
    " 'f95',\n",
    " 'f96',\n",
    " 'f99',\n",
    " 'f100',\n",
    " 'f101',\n",
    " 'f103',\n",
    " 'f105',\n",
    " 'f108',\n",
    " 'f112',\n",
    " 'f118',\n",
    " 'f119',\n",
    " 'f125',\n",
    " 'f127',\n",
    " 'f129',\n",
    " 'f130',\n",
    " 'f131',\n",
    " 'f134',\n",
    " 'f136',\n",
    " 'f138',\n",
    " 'f139',\n",
    " 'f140',\n",
    " 'f143',\n",
    " 'f144',\n",
    " 'f146',\n",
    " 'f150',\n",
    " 'f154',\n",
    " 'f156',\n",
    " 'f157',\n",
    " 'f163',\n",
    " 'f169',\n",
    " 'f175',\n",
    " 'f179',\n",
    " 'f184',\n",
    " 'f188',\n",
    " 'f191',\n",
    " 'f192',\n",
    " 'f195',\n",
    " 'f199',\n",
    " 'f200',\n",
    " 'f201',\n",
    " 'f210',\n",
    " 'f211',\n",
    " 'f212',\n",
    " 'f213',\n",
    " 'f214',\n",
    " 'f219',\n",
    " 'f222',\n",
    " 'f227',\n",
    " 'f231',\n",
    " 'f238',\n",
    " 'f240',\n",
    " 'f241']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = selector.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_csv('outputs\\\\feature_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function does 3-fold crossvalidation with catboostclassifier          \n",
    "def crossvaltest(params, train_set, train_label, cat_dims, n_splits=3):\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "#     kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_set):\n",
    "        train = train_set.iloc[train_index,:]\n",
    "        test = train_set.iloc[test_index,:]\n",
    "\n",
    "        labels = train_label.iloc[train_index]\n",
    "        test_labels = train_label.iloc[test_index]\n",
    "\n",
    "        clf = CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims)\n",
    "\n",
    "        res.append(np.mean(clf.predict(test)==np.ravel(test_labels)))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs grid search on several parameters\n",
    "def catboost_param_tune(params, train_set, train_label, cat_dims=None, n_splits=3):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(\n",
    "#         ps.grid_search(['border_count']),\n",
    "#         ps.grid_search(['ctr_border_count']),\n",
    "        ps.grid_search(['l2_leaf_reg']),\n",
    "        ps.grid_search(['iterations','learning_rate']),\n",
    "        ps.grid_search(['depth'])):\n",
    "        res = crossvaltest(prms, train_set, train_label, cat_dims, n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res, prms)\n",
    "        print(res, prms, ps, 'best:', ps.bestscore(), ps.bestparam())\n",
    "    return ps.bestparam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"loss_function\": \"CrossEntropy\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"custom_metric\": ['AUC:hints=skip_train~false'],\n",
    "#     \"class_weights\": class_weights,\n",
    "#     \"one_hot_max_size\": 31,\n",
    "#     \"depth\": [3, 1, 2, 6, 4, 5, 7, 8, 9, 10],\n",
    "    \"depth\": [5, 7],\n",
    "    \"iterations\": [50000],\n",
    "#     \"learning_rate\": [0.03, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\": [0.1],\n",
    "#     \"l2_leaf_reg\": [3, 1, 5, 10, 100],\n",
    "    \"l2_leaf_reg\": [5, 10],\n",
    "#     \"border_count\": [32, 5, 10, 20, 50, 100, 200],\n",
    "#     \"ctr_border_count\": [50, 5, 10, 20, 100, 200],\n",
    "    \"nan_mode\": \"Max\",\n",
    "    \"thread_count\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "bestparams = catboost_param_tune(\n",
    "    params=params,\n",
    "#     train_set=X_train,\n",
    "    train_set=X_train[summary[\"selected_features_names\"]],\n",
    "    train_label=y_train,\n",
    "#     cat_dims=[1],\n",
    "    n_splits=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'loss_function': 'MultiClass',\n",
    " 'eval_metric': 'Accuracy',\n",
    " 'depth': 3,\n",
    " 'iterations': 500,\n",
    " 'learning_rate': 0.03,\n",
    " 'l2_leaf_reg': 5,\n",
    " 'nan_mode': 'Max',\n",
    " 'thread_count': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams.update({'iterations': 1500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with tuned parameters    \n",
    "model = CatBoostClassifier(\n",
    "    **bestparams,\n",
    "#     loss_function=\"MultiClass\",\n",
    "    class_weights=class_weights\n",
    "#     cat_features=[1]\n",
    ")\n",
    "# clf.fit(train_set, np.ravel(train_label), cat_features=cat_dims)\n",
    "# res = clf.predict(test_set)\n",
    "# print('error:',1-np.mean(res==np.ravel(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train[summary[\"selected_features_names\"]],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CatBoost model is fitted: True\n",
    "CatBoost model parameters:\n",
    "{'iterations': 1500, 'learning_rate': 0.03, 'depth': 3, 'l2_leaf_reg': 5, 'loss_function': 'MultiClass', 'nan_mode': 'Max', 'class_weights': {2: 0.56552175, 1: 0.367034, 3: 0.048928, 7: 0.01556525, 6: 0.0028565, 4: 9.425e-05, 5: 2.5e-07}, 'eval_metric': 'Accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_all_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = model.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata[\"model_guid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata[\"train_finish_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata[\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[summary[\"selected_features_names\"]])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test[summary[\"selected_features_names\"]])\n",
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skplt.metrics.plot_roc(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skplt.metrics.plot_precision_recall(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skplt.metrics.plot_ks_statistic(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skplt.metrics.plot_lift_curve(y_test, y_prob)\n",
    "# plt.legend(loc='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skplt.metrics.plot_cumulative_gain(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (unique, counts) = np.unique(np.array(y_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies = np.asarray((unique, counts)).T\n",
    "# frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy score: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Balanced score: \" + str(balanced_accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(figsize=(10,10))\n",
    "# ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', annot_kws={\"size\": 40, \"weight\": \"bold\"})\n",
    "# labels = ['NIE LAPS', 'LAPS']\n",
    "# ax.set_xticklabels(labels, fontsize=25);\n",
    "# ax.set_yticklabels(labels, fontsize=25);\n",
    "# ax.set_ylabel('True label', fontsize=30);\n",
    "# ax.set_xlabel('Predicted label', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train[summary[\"selected_features_names\"]].corr()\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "fig = sns.heatmap(corrmat, vmax=1, square=True, annot=True)\n",
    "fig.figure.savefig(\"correlation_matrix_selected_features.jpg\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"correlation_matrix_selected_features.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_target = summary[\"selected_features_names\"] + [TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(X_train, y_train, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = df[selected_features_target].corr()[\"Cover_Type\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,20))\n",
    "sns_plot = sns.heatmap(corr_target.sort_values(ascending=False).to_frame(),annot=True, annot_kws={'size':12},cmap=\"GnBu\")\n",
    "plt.show()\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"correlation_target.jpg\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_columns = pd.DataFrame(corr_target.sort_values(ascending=False)).T.columns\n",
    "correlated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()\n",
    "# # fig = sns.pairplot(df[selected_features_target], size = 5, hue=df[selected_features_target].columns[-1])\n",
    "# fig = sns.pairplot(df[selected_features_target].sample(frac=0.001), size=3, hue=df[selected_features_target].columns[-1])\n",
    "# plt.show();\n",
    "# fig.savefig(\"pair_plots.jpg\")\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"pair_plots.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NO ALL CLASSES WERE REPRESENTED!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1 SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The function used in most kernels\n",
    "# def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "#     assert( len(actual) == len(pred) )\n",
    "#     all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "#     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "#     totalLosses = all[:,0].sum()\n",
    "#     giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "#     giniSum -= (len(actual) + 1) / 2.\n",
    "#     return giniSum / len(actual)\n",
    " \n",
    "# def gini_normalized(a, p):\n",
    "#     return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini_normalized(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVING FEATURES NOT IMPACTING LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_exclude = {\n",
    "    \"feature_index\": [\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"6\",\n",
    "        \"8\",\n",
    "        \"14\",\n",
    "        \"16\",\n",
    "        \"17\",\n",
    "        \"18\",\n",
    "        \"19\",\n",
    "        \"20\",\n",
    "        \"21\",\n",
    "        \"22\",\n",
    "        \"28\",\n",
    "        \"38\",\n",
    "        \"25\"\n",
    "    ],\n",
    "    \"feature_name\": [\n",
    "        \"Aspect\",\n",
    "        \"Slope\",\n",
    "        \"Hillshade_9am\",\n",
    "        \"Hillshade_3am\",\n",
    "        \"Soil_Type1\",\n",
    "        \"Soil_Type3\",\n",
    "        \"Soil_Type4\",\n",
    "        \"Soil_Type5\",\n",
    "        \"Soil_Type6\",\n",
    "        \"Soil_Type7\",\n",
    "        \"Soil_Type8\",\n",
    "        \"Soil_Type9\",\n",
    "        \"Soil_Type15\",\n",
    "        \"Soil_Type25\",\n",
    "        \"Soil_Type12\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = pd.DataFrame.from_dict(features_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude['feature_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:, ~X_train.columns.isin(to_exclude['feature_name'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train.loc[:, ~X_train.columns.isin(to_exclude['feature_name'])],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.loc[:, ~X_train.columns.isin(to_exclude['feature_name'])])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2  SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3 - ONLY 'Elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train['Elevation'],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.loc[:, ~X_train.columns.isin(to_exclude['feature_name'])])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3  SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Elevation' is responsible for ~0.88 of Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4 -- ADDINING Soil_Type23, Soil_Type40 Hillshade_Noon TO MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"selected_features_names\"] + [\"Soil_Type23\", \"Soil_Type40\", \"Hillshade_Noon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"] + [\"Soil_Type23\", \"Soil_Type40\", \"Hillshade_Noon\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train[summary[\"selected_features_names\"] + [\"Soil_Type23\", \"Soil_Type40\", \"Hillshade_Noon\"]],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.loc[:, ~X_train.columns.isin(to_exclude['feature_name'])])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4  SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5 --feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/chryzal/features-engineering-for-you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    \"Horizontal_Distance_To_Hydrology\": \"x_dist_hydrlgy\",\n",
    "    \"Vertical_Distance_To_Hydrology\": \"y_dist_hydrlgy\",\n",
    "    \"Horizontal_Distance_To_Roadways\": \"x_dist_rdwys\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\": \"x_dist_firepts\"\n",
    "}\n",
    "\n",
    "X_train.rename(new_names, axis=1, inplace=True)\n",
    "X_test.rename(new_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Aspect\"][X_train[\"Aspect\"] < 0] += 360\n",
    "X_train[\"Aspect\"][X_train[\"Aspect\"] > 359] -= 360\n",
    "\n",
    "X_test[\"Aspect\"][X_test[\"Aspect\"] < 0] += 360\n",
    "X_test[\"Aspect\"][X_test[\"Aspect\"] > 359] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhhattan distance to Hydrology\n",
    "X_train[\"mnhttn_dist_hydrlgy\"] = np.abs(X_train[\"x_dist_hydrlgy\"]) + np.abs(X_train[\"y_dist_hydrlgy\"])\n",
    "X_test[\"mnhttn_dist_hydrlgy\"] = np.abs(X_test[\"x_dist_hydrlgy\"]) + np.abs(X_test[\"y_dist_hydrlgy\"])\n",
    "\n",
    "# Euclidean distance to Hydrology\n",
    "X_train[\"ecldn_dist_hydrlgy\"] = (X_train[\"x_dist_hydrlgy\"]**2 + X_train[\"y_dist_hydrlgy\"]**2)**0.5\n",
    "X_test[\"ecldn_dist_hydrlgy\"] = (X_test[\"x_dist_hydrlgy\"]**2 + X_test[\"y_dist_hydrlgy\"]**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n",
    "X_test.loc[X_test[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n",
    "\n",
    "X_train.loc[X_train[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n",
    "X_test.loc[X_test[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n",
    "\n",
    "X_train.loc[X_train[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n",
    "X_test.loc[X_test[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n",
    "\n",
    "X_train.loc[X_train[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n",
    "X_test.loc[X_test[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n",
    "\n",
    "X_train.loc[X_train[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n",
    "X_test.loc[X_test[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n",
    "\n",
    "X_train.loc[X_train[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n",
    "X_test.loc[X_test[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_Hillshade = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n",
    "soil_features = [x for x in X_train.columns if x.startswith(\"Soil_Type\")]\n",
    "wilderness_features = [x for x in X_train.columns if x.startswith(\"Wilderness_Area\")]\n",
    "\n",
    "def addFeature(X):\n",
    "    # Thanks @mpwolke : https://www.kaggle.com/mpwolke/tooezy-where-are-you-no-camping-here\n",
    "    X[\"Soil_Count\"] = X[soil_features].apply(sum, axis=1)\n",
    "\n",
    "    # Thanks @yannbarthelemy : https://www.kaggle.com/yannbarthelemy/tps-december-first-simple-feature-engineering\n",
    "    X[\"Wilderness_Area_Count\"] = X[wilderness_features].apply(sum, axis=1)\n",
    "    X[\"Hillshade_mean\"] = X[features_Hillshade].mean(axis=1)\n",
    "    X['amp_Hillshade'] = X[features_Hillshade].max(axis=1) - X[features_Hillshade].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addFeature(X_train)\n",
    "addFeature(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"mnhttn_dist_hydrlgy\",\n",
    "    \"ecldn_dist_hydrlgy\",\n",
    "    \"Slope\",\n",
    "    \"x_dist_hydrlgy\",\n",
    "    \"y_dist_hydrlgy\",\n",
    "    \"x_dist_rdwys\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"x_dist_firepts\",\n",
    "    \"Soil_Count\",\n",
    "    \"Wilderness_Area_Count\",\n",
    "    \"Hillshade_mean\",\n",
    "    \"amp_Hillshade\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train[cols] = scaler.fit_transform(X_train[cols])\n",
    "X_test[cols] = scaler.transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MODEL 5 - FEATURE SELECTOR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CatBoost model parameters:\n",
    "{'iterations': 1500, 'learning_rate': 0.03, 'depth': 3, 'l2_leaf_reg': 5, 'loss_function': 'MultiClass', 'nan_mode': 'Max', 'class_weights': {2: 0.56552175, 1: 0.367034, 3: 0.048928, 7: 0.01556525, 6: 0.0028565, 4: 9.425e-05, 5: 2.5e-07}, 'eval_metric': 'Accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selector = CatBoostClassifier(\n",
    "    #     loss_function=\"CrossEntropy\", # class weights takes effect only with Logloss, MultiClass, MultiClassOneVsAll\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    class_weights=class_weights,\n",
    "#     one_hot_max_size=31,\n",
    "    depth=3,\n",
    "    iterations= 1000,\n",
    "    l2_leaf_reg= 5,\n",
    "    learning_rate= 0.03,\n",
    "    nan_mode=\"Max\"\n",
    "#     cat_features=categorical_features_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names= X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features_index, feature_names=feature_names)\n",
    "#test_pool = Pool(X_test, y_test, cat_features=categorical_features_index, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'0-' + str(X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = selector.select_features(\n",
    "    train_pool, # X_train, y_train\n",
    "    #eval_set=test_pool, # The validation dataset or datasets used for the following processes: overfitting detector, best iteration selection, monitoring metrics changes\n",
    "    features_for_select='0-' + str(X_test.shape[1]-1), # Features which participate in the selection.\n",
    "    num_features_to_select=15, # The number of features to select from features_for_select.\n",
    "    steps=3, # The number of times for training the model. Use more steps for more accurate selection\n",
    "    algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues, # the most accurate method\n",
    "    shap_calc_type=EShapCalcType.Exact, # The method of the SHAP values calculations ordered by accuracy: Approximate, Regular, Exact\n",
    "#     train_final_model=True, # If specified, then the model with selected features will be trained after features selection.\n",
    "    #logging_level='Silent', # optimized metric, elapsed time of training, remaining time of training\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary[\"selected_features_names\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Elevation',\n",
    " 'Horizontal_Distance_To_Hydrology',\n",
    " 'Vertical_Distance_To_Hydrology',\n",
    " 'Horizontal_Distance_To_Roadways',\n",
    " 'Horizontal_Distance_To_Fire_Points',\n",
    " 'Wilderness_Area3',\n",
    " 'Wilderness_Area4',\n",
    " 'Soil_Type22',\n",
    " 'Soil_Type38',\n",
    " 'Soil_Type39']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Elevation',\n",
    " 'y_dist_hydrlgy',\n",
    " 'x_dist_rdwys',\n",
    " 'Hillshade_Noon',\n",
    " 'x_dist_firepts',\n",
    " 'Wilderness_Area1',\n",
    " 'Wilderness_Area3',\n",
    " 'Wilderness_Area4',\n",
    " 'Soil_Type4',\n",
    " 'Soil_Type22',\n",
    " 'Soil_Type23',\n",
    " 'Soil_Type38',\n",
    " 'Soil_Type39',\n",
    " 'mnhttn_dist_hydrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams.update({'iterations': 1500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with tuned parameters    \n",
    "model = CatBoostClassifier(\n",
    "    **bestparams,\n",
    "#     loss_function=\"MultiClass\",\n",
    "    class_weights=class_weights\n",
    "#     cat_features=[1]\n",
    ")\n",
    "# clf.fit(train_set, np.ravel(train_label), cat_features=cat_dims)\n",
    "# res = clf.predict(test_set)\n",
    "# print('error:',1-np.mean(res==np.ravel(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train[summary[\"selected_features_names\"]],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CatBoost model is fitted: True\n",
    "CatBoost model parameters:\n",
    "{'iterations': 1500, 'learning_rate': 0.03, 'depth': 3, 'l2_leaf_reg': 5, 'loss_function': 'MultiClass', 'nan_mode': 'Max', 'class_weights': {2: 0.56552175, 1: 0.367034, 3: 0.048928, 7: 0.01556525, 6: 0.0028565, 4: 9.425e-05, 5: 2.5e-07}, 'eval_metric': 'Accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[summary[\"selected_features_names\"]])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5  SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 6 - ADDING x_dist_hydrlgy,  Soil_Type2, Soil_Type10, ecldn_dist_hydrlgy, Soil_Type40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist_hydrlgy\n",
    "Soil_Type2\n",
    "Soil_Type10\n",
    "ecldn_dist_hydrlgy\n",
    "Soil_Type40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary[\"selected_features_names\"] + [\"x_dist_hydrlgy\", \"Soil_Type2\", \"Soil_Type10\", \"ecldn_dist_hydrlgy\", \"Soil_Type40\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Elevation',\n",
    " 'Horizontal_Distance_To_Hydrology',\n",
    " 'Vertical_Distance_To_Hydrology',\n",
    " 'Horizontal_Distance_To_Roadways',\n",
    " 'Horizontal_Distance_To_Fire_Points',\n",
    " 'Wilderness_Area3',\n",
    " 'Wilderness_Area4',\n",
    " 'Soil_Type22',\n",
    " 'Soil_Type38',\n",
    " 'Soil_Type39']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Elevation',\n",
    " 'y_dist_hydrlgy',\n",
    " 'x_dist_rdwys',\n",
    " 'Hillshade_Noon',\n",
    " 'x_dist_firepts',\n",
    " 'Wilderness_Area1',\n",
    " 'Wilderness_Area3',\n",
    " 'Wilderness_Area4',\n",
    " 'Soil_Type4',\n",
    " 'Soil_Type22',\n",
    " 'Soil_Type23',\n",
    " 'Soil_Type38',\n",
    " 'Soil_Type39',\n",
    " 'mnhttn_dist_hydrl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Elevation',\n",
    " 'y_dist_hydrlgy',\n",
    " 'x_dist_rdwys',\n",
    " 'Hillshade_Noon',\n",
    " 'x_dist_firepts',\n",
    " 'Wilderness_Area1',\n",
    " 'Wilderness_Area3',\n",
    " 'Wilderness_Area4',\n",
    " 'Soil_Type4',\n",
    " 'Soil_Type22',\n",
    " 'Soil_Type23',\n",
    " 'Soil_Type38',\n",
    " 'Soil_Type39',\n",
    " 'mnhttn_dist_hydrlgy',\n",
    " 'Soil_Count',\n",
    " 'x_dist_hydrlgy',\n",
    " 'Soil_Type2',\n",
    " 'Soil_Type10',\n",
    " 'ecldn_dist_hydrlgy',\n",
    " 'Soil_Type40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams.update({'iterations': 1500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with tuned parameters    \n",
    "model = CatBoostClassifier(\n",
    "    **bestparams,\n",
    "#     loss_function=\"MultiClass\",\n",
    "    class_weights=class_weights\n",
    "#     cat_features=[1]\n",
    ")\n",
    "# clf.fit(train_set, np.ravel(train_label), cat_features=cat_dims)\n",
    "# res = clf.predict(test_set)\n",
    "# print('error:',1-np.mean(res==np.ravel(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[summary[\"selected_features_names\"] + [\"x_dist_hydrlgy\", \"Soil_Type2\", \"Soil_Type10\", \"ecldn_dist_hydrlgy\", \"Soil_Type40\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    X_train[summary[\"selected_features_names\"] + [\"x_dist_hydrlgy\", \"Soil_Type2\", \"Soil_Type10\", \"ecldn_dist_hydrlgy\", \"Soil_Type40\"]],\n",
    "    y_train,\n",
    "#     eval_set=(X_test[summary[\"selected_features_names\"]], y_test),\n",
    "#     use_best_model=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost model is fitted: ' + str(model.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CatBoost model is fitted: True\n",
    "CatBoost model parameters:\n",
    "{'iterations': 1500, 'learning_rate': 0.03, 'depth': 3, 'l2_leaf_reg': 5, 'loss_function': 'MultiClass', 'nan_mode': 'Max', 'class_weights': {2: 0.56552175, 1: 0.367034, 3: 0.048928, 7: 0.01556525, 6: 0.0028565, 4: 9.425e-05, 5: 2.5e-07}, 'eval_metric': 'Accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(\n",
    "    prettified=True,\n",
    "    thread_count=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[summary[\"selected_features_names\"] + [\"x_dist_hydrlgy\", \"Soil_Type2\", \"Soil_Type10\", \"ecldn_dist_hydrlgy\", \"Soil_Type40\"]])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = pd.DataFrame(y_pred, index=X_test.index, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 6 PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission_\" + date_string + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission.to_csv(\"outputs\\submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 6  SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! kaggle competitions submit tabular-playground-series-oct-2021 -f outputs\\submission.csv -m \"Submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
